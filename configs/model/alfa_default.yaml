_target_: src.models.task_model.TaskModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.0001
  weight_decay: 0.0

scheduler:
  _target_: transformers.get_linear_schedule_with_warmup
  _partial_: true
  num_warmup_steps: 100
  num_training_steps:  "${eval:'${trainer.max_epochs} * 10000'}"                                               

encoder_type: 'whisper/tiny'
head_type: 'linear'