_target_: src.models.task_model.TaskModule

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.0005
  weight_decay: 0.0

scheduler:
  _target_: transformers.get_linear_schedule_with_warmup
  _partial_: true
  num_warmup_steps: 100
  num_training_steps:  "${eval:'${trainer.max_epochs} * 16500'}"                                               

encoder_type: 'whisper/tiny'
head_type: 'last_output'
task_name: ${task.task_name}