{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4d53e8-2110-40dd-97be-bbce5681db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['savefig.facecolor'] = 'white'\n",
    "plt.rcParams['savefig.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5b6cb4-e397-47e9-8501-2aaf1a66362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54c10ae2-9375-4273-9bcc-1892c92e81b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Extension horovod.torch has not been built: /home/user/conda/lib/python3.7/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-37m-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dataclasses\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "import tqdm \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26e3e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from romashka.models import TransactionsModel\n",
    "from romashka.tools import (make_time_batch, \n",
    "                   calculate_embedding_size)\n",
    "\n",
    "from romashka.data_generators import (batches_generator, \n",
    "                             cat_features_names, \n",
    "                             num_features_names, \n",
    "                             meta_features_names)\n",
    "\n",
    "from romashka.pl_dataloader import TransactionQADataset, TransactionQADataModule\n",
    "from romashka.transactions_qa.tqa_model import TransactionQAModel\n",
    "from romashka.transactions_qa.utils import get_projections_maps\n",
    "from romashka.transactions_qa.tasks import AbstractTask, AutoTask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a57d97",
   "metadata": {},
   "source": [
    "### Base loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e22074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical embeddings projections:\n",
      "{'card_type': (175, 29),\n",
      " 'city': (163, 28),\n",
      " 'country': (24, 9),\n",
      " 'currency': (11, 6),\n",
      " 'day_of_week': (7, 5),\n",
      " 'ecommerce_flag': (3, 3),\n",
      " 'hour': (24, 9),\n",
      " 'income_flag': (3, 3),\n",
      " 'mcc': (108, 22),\n",
      " 'mcc_category': (28, 10),\n",
      " 'operation_kind': (7, 5),\n",
      " 'operation_type': (22, 9),\n",
      " 'operation_type_group': (4, 3),\n",
      " 'payment_system': (7, 5),\n",
      " 'weekofyear': (53, 15)}\n",
      "\n",
      "Numeric embeddings projections:\n",
      "{'amnt': (10, 6), 'days_before': (23, 9), 'hour_diff': (10, 6)}\n",
      "\n",
      "Meta embeddings projections:\n",
      "{'product': (5, 4)}\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "projections_maps = get_projections_maps(relative_folder=\"../romashka\")\n",
    "\n",
    "print(f\"\\nCategorical embeddings projections:\")   \n",
    "pprint(projections_maps['cat_embedding_projections'])\n",
    "\n",
    "print(f\"\\nNumeric embeddings projections:\")   \n",
    "pprint(projections_maps['num_embedding_projections'])\n",
    "\n",
    "print(f\"\\nMeta embeddings projections:\")   \n",
    "pprint(projections_maps['meta_embedding_projections'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b55c781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Transactions model...\n",
      "USING whisper\n"
     ]
    }
   ],
   "source": [
    "# Loading Transactions model & weights\n",
    "print(f\"Loading Transactions model...\")\n",
    "\n",
    "transactions_model_encoder_type = \"whisper/tiny\"\n",
    "transactions_model_head_type = \"next\"\n",
    "\n",
    "\n",
    "transactions_model_config = {\n",
    "    \"cat_features\": cat_features_names,\n",
    "    \"cat_embedding_projections\": projections_maps.get('cat_embedding_projections'),\n",
    "    \"num_features\": num_features_names,\n",
    "    \"num_embedding_projections\": projections_maps.get('num_embedding_projections'),\n",
    "    \"meta_features\": meta_features_names,\n",
    "    \"meta_embedding_projections\": projections_maps.get('meta_embedding_projections'),\n",
    "    \"encoder_type\": transactions_model_encoder_type,\n",
    "    \"head_type\": transactions_model_head_type,\n",
    "    \"embedding_dropout\": 0.1\n",
    "}\n",
    "transactions_model = TransactionsModel(**transactions_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a924bca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Language model: `google/flan-t5-small`...\n"
     ]
    }
   ],
   "source": [
    "# Configure and load from HF hub LM model\n",
    "language_model_name_or_path = \"google/flan-t5-small\"\n",
    "use_fast_tokenizer = True\n",
    "\n",
    "print(f\"Loading Language model: `{language_model_name_or_path}`...\")\n",
    "config_kwargs = {\n",
    "    \"use_auth_token\": None,\n",
    "    \"return_unused_kwargs\": True\n",
    "}\n",
    "\n",
    "tokenizer_kwargs = {\n",
    "    \"use_fast\": use_fast_tokenizer,\n",
    "    \"use_auth_token\": None,\n",
    "    \"do_lowercase\": False\n",
    "}\n",
    "\n",
    "config, unused_kwargs = AutoConfig.from_pretrained(\n",
    "    language_model_name_or_path, **config_kwargs\n",
    ")\n",
    "# Download vocabulary from huggingface.co and define model-specific arguments\n",
    "tokenizer = AutoTokenizer.from_pretrained(language_model_name_or_path, **tokenizer_kwargs)\n",
    "\n",
    "# Download model from huggingface.co and cache.\n",
    "lm_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    language_model_name_or_path,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e72b5c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train contains files: 10 \n",
      "Validation contains files: 5 \n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"../data\").resolve()\n",
    "\n",
    "TRAIN_BUCKETS_PATH = DATA_PATH / \"train_buckets\"\n",
    "VAL_BUCKETS_PATH = DATA_PATH / \"val_buckets\"\n",
    "\n",
    "n_train_files = len(list(TRAIN_BUCKETS_PATH.glob(\"*.pkl\")))\n",
    "print(f\"Train contains files: {n_train_files} \")\n",
    "\n",
    "n_val_files = len(list(VAL_BUCKETS_PATH.glob(\"*.pkl\")))\n",
    "print(f\"Validation contains files: {n_val_files} \")\n",
    "\n",
    "TRAIN_METAFILE_PATH = str(DATA_PATH / 'train.csv')\n",
    "VAL_METAFILE_PATH = str(DATA_PATH / 'val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d159c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train contains files: 10\n",
      "\t /home/jovyan/data/train_buckets/processed_chunk_000.pkl\n",
      "\t /home/jovyan/data/train_buckets/processed_chunk_001.pkl\n",
      "\t /home/jovyan/data/train_buckets/processed_chunk_002.pkl\n",
      "\t /home/jovyan/data/train_buckets/processed_chunk_003.pkl\n",
      "\t /home/jovyan/data/train_buckets/processed_chunk_004.pkl\n",
      "\t /home/jovyan/data/train_buckets/processed_chunk_005.pkl\n",
      "\t /home/jovyan/data/train_buckets/processed_chunk_006.pkl\n",
      "\t /home/jovyan/data/train_buckets/processed_chunk_007.pkl\n",
      "\t /home/jovyan/data/train_buckets/processed_chunk_008.pkl\n",
      "\t /home/jovyan/data/train_buckets/processed_chunk_009.pkl\n",
      "\n",
      "Val contains files: 5\n",
      "\t /home/jovyan/data/val_buckets/processed_chunk_000.pkl\n",
      "\t /home/jovyan/data/val_buckets/processed_chunk_001.pkl\n",
      "\t /home/jovyan/data/val_buckets/processed_chunk_002.pkl\n",
      "\t /home/jovyan/data/val_buckets/processed_chunk_003.pkl\n",
      "\t /home/jovyan/data/val_buckets/processed_chunk_004.pkl\n"
     ]
    }
   ],
   "source": [
    "data_files = {}\n",
    "\n",
    "train_dataset_files = os.listdir(str(TRAIN_BUCKETS_PATH))\n",
    "n_train_files = len(train_dataset_files)\n",
    "print(f\"Train contains files: {n_train_files}\")\n",
    "train_dataset_files = sorted([os.path.join(str(TRAIN_BUCKETS_PATH), x) for x in train_dataset_files])\n",
    "data_files[\"train\"] = train_dataset_files\n",
    "\n",
    "for fn in train_dataset_files:\n",
    "    print(\"\\t\", fn)\n",
    "\n",
    "val_dataset_files = os.listdir(str(VAL_BUCKETS_PATH))\n",
    "n_val_files = len(val_dataset_files)\n",
    "print(f\"\\nVal contains files: {n_val_files}\")\n",
    "val_dataset_files = sorted([os.path.join(str(VAL_BUCKETS_PATH), x) for x in val_dataset_files])\n",
    "data_files[\"validation\"] = val_dataset_files\n",
    "\n",
    "for fn in val_dataset_files:\n",
    "    print(\"\\t\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f209c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_config = {\n",
    "    'dataset': data_files['validation'],\n",
    "    'min_seq_len': 0,\n",
    "    'max_seq_len': 250,\n",
    "    'seed': 42, \n",
    "    'buffer_size': 0,\n",
    "    'batch_size': 32,\n",
    "    'generator_batch_size': 1,\n",
    "    'num_workers': 5\n",
    "}\n",
    "\n",
    "val_ds = TransactionQADataModule(val_dataset_config=val_dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b78c14",
   "metadata": {},
   "source": [
    "### Need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cbd354d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 11:54:08,890 - [INFO] - Tasks - (task_abstract.py).extend_vocabulary(163) - Added to tokenizer: 2 tokens.\n",
      "2023-04-06 11:54:08,891 - [INFO] - Tasks - (task_abstract.py).extend_vocabulary(169) - Notice: resize_token_embeddings of a model to adapt to the size of the new vocabulary!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got task_names: ['default'] with task_kwargs: [{'num_options': 6}]\n",
      "Created 1 tasks.\n"
     ]
    }
   ],
   "source": [
    "# Create tasks\n",
    "tasks = []\n",
    "task_names = ['default']\n",
    "task_kwargs = [{\"num_options\": 6 }] # ground truth + 5 additional options\n",
    "\n",
    "if isinstance(task_names, str):\n",
    "    task_names = eval(task_names)\n",
    "task_kwargs = task_kwargs\n",
    "if isinstance(task_kwargs, str):\n",
    "    task_kwargs = eval(task_kwargs)\n",
    "print(f\"Got task_names: {task_names} with task_kwargs: {task_kwargs}\")\n",
    "\n",
    "for task_i, task_name in enumerate(task_names):\n",
    "    task_kwargs = task_kwargs[task_i] if task_i < len(task_kwargs) else {}\n",
    "    if \"tokenizer\" not in task_kwargs:\n",
    "        task_kwargs['tokenizer'] = tokenizer\n",
    "    task = AutoTask.get(task_name=task_name, **task_kwargs)\n",
    "    tasks.append(task)\n",
    "print(f\"Created {len(tasks)} tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad84c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 11:54:09,370 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(120) - Running in `single task` settingwith a single task: default provided.\n",
      "2023-04-06 11:54:09,371 - [INFO] - TransactionQAModel - (tqa_model.py)._set_model_type(155) - Language model type: `encoder-decoder`\n",
      "2023-04-06 11:54:09,372 - [INFO] - TransactionQAModel - (tqa_model.py)._resize_text_embeddings(165) - LM initial `num_embeddings`: 32128, `embedding_dim`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dimension of embedding model: 384\n",
      "Input dimension of autoregressive model: 512\n",
      "Creating linear connector from 384 to 512 and move to device: cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 11:54:09,611 - [INFO] - TransactionQAModel - (tqa_model.py)._resize_text_embeddings(177) - LM resized `num_embeddings`: 32102, `embedding_dim`: 512\n",
      "2023-04-06 11:54:09,616 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(131) - Freezing transaction model's parameters...\n",
      "2023-04-06 11:54:09,617 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(136) - Freezing language model's parameters...\n"
     ]
    }
   ],
   "source": [
    "from transactions_qa.tqa_model import TransactionQAModel\n",
    "\n",
    "# Create general Tranactions QA model\n",
    "max_steps = 100_000\n",
    "warmup_steps = 1000\n",
    "do_freeze_transactions_model = True\n",
    "do_freeze_language_model = True\n",
    "do_freeze_connector = False\n",
    "\n",
    "transactionsQA_model_config = {\n",
    "    \"warmup_steps\": warmup_steps,\n",
    "    \"training_steps\": max_steps,\n",
    "    \"do_freeze_tm\": do_freeze_transactions_model,\n",
    "    \"do_freeze_lm\": do_freeze_language_model,\n",
    "    \"do_freeze_connector\": do_freeze_connector,\n",
    "    \"connector_input_size\": 384,\n",
    "}\n",
    "model = TransactionQAModel(\n",
    "    language_model=lm_model,\n",
    "    transaction_model=transactions_model,\n",
    "    tokenizer=tokenizer,\n",
    "    tasks=tasks,\n",
    "    **transactionsQA_model_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375231e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jovyan/checkpoints/checkpoints/shuffle-1k-tqa_flan-t5-small_300k-steps_default-binary/last.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_662107/4120120722.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/jovyan/checkpoints/checkpoints/shuffle-1k-tqa_flan-t5-small_300k-steps_default-binary/last.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.imgenv-afilatov-dev-6-0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-afilatov-dev-6-0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-afilatov-dev-6-0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyan/checkpoints/checkpoints/shuffle-1k-tqa_flan-t5-small_300k-steps_default-binary/last.ckpt'"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load('/home/jovyan/checkpoints/checkpoints/shuffle-1k-tqa_flan-t5-small_300k-steps_default-binary/last.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50e6b8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a97055",
   "metadata": {},
   "source": [
    "### AUC, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f7bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug\n",
    "ind_pos = model.tokenizer(\"Yes\").input_ids[0]\n",
    "ind_neg = model.tokenizer(\"No\").input_ids[0]\n",
    "\n",
    "list_targets = []\n",
    "list_preds = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_ds.val_dataloader()):\n",
    "        model.eval()\n",
    "        outputs, answers = model.model_step(batch)\n",
    "\n",
    "        targets = (answers[:, -2] == ind_pos).long()\n",
    "        preds = torch.sigmoid(outputs.logits[:, 0, ind_pos] - outputs.logits[:, 0, ind_neg])\n",
    "\n",
    "        list_targets.extend(targets.tolist())\n",
    "        list_preds.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3bb748",
   "metadata": {},
   "source": [
    "### Evaluate transaction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d30d778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f480713",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(val_ds.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "abebd52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef259a04acba480aa75e12d147d17436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_662107/1697799593.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtarget_feature_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_feature_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrx_index\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "list_preds = []\n",
    "list_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    transactions_model.eval()\n",
    "    for batch in tqdm(val_ds.val_dataloader()):\n",
    "        p = transactions_model(batch)\n",
    "\n",
    "        trx_index = batch['mask'].sum(1, keepdim=True) - 1\n",
    "        input_labels = torch.gather(batch['num_features'][0], 1, trx_index)\n",
    "        target = (input_labels < 0.41).long().squeeze()\n",
    "\n",
    "        target_feature_batch = p['num_features'][0].squeeze()\n",
    "        preds = torch.gather(target_feature_batch, 1, trx_index - 1)\n",
    "        pred = (preds < 0.41).long().squeeze()\n",
    "\n",
    "        list_preds.extend(pred)\n",
    "        list_targets.extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ff15524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3484180497925311"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(list_preds, list_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83462aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ff2a09b934b25be9a8b176e9d1e80ece927d491d3847c62b1a0ae23e4142515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
