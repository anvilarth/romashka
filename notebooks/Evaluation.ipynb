{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4d53e8-2110-40dd-97be-bbce5681db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['savefig.facecolor'] = 'white'\n",
    "plt.rcParams['savefig.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f5b6cb4-e397-47e9-8501-2aaf1a66362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c10ae2-9375-4273-9bcc-1892c92e81b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "import tqdm \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e3e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transactions_qa.tqa_model import TransactionQAModel\n",
    "from src.models.components.models import TransactionsModel\n",
    "from src.utils.tools import (make_time_batch, \n",
    "                   calculate_embedding_size)\n",
    "\n",
    "from src.data.alfa.components import ( \n",
    "                             cat_features_names, \n",
    "                             num_features_names, \n",
    "                             meta_features_names)\n",
    "\n",
    "from src.data import AlfaDataModule \n",
    "from src.transactions_qa.tqa_model import TransactionQAModel\n",
    "from src.transactions_qa.utils import get_projections_maps\n",
    "from src.tasks import AbstractTask, AutoTask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a57d97",
   "metadata": {},
   "source": [
    "### Loading transaction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95db62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transaction_model(encoder_type='whisper/tiny', head_type='next'):\n",
    "    projections_maps = get_projections_maps(relative_folder=\"..\")\n",
    "    # Loading Transactions model & weights\n",
    "    print(f\"Loading Transactions model...\")\n",
    "\n",
    "    transactions_model_encoder_type = encoder_type\n",
    "    transactions_model_head_type = head_type\n",
    "\n",
    "\n",
    "    transactions_model_config = {\n",
    "        \"cat_features\": cat_features_names,\n",
    "        \"cat_embedding_projections\": projections_maps.get('cat_embedding_projections'),\n",
    "        \"num_features\": num_features_names,\n",
    "        \"num_embedding_projections\": projections_maps.get('num_embedding_projections'),\n",
    "        \"meta_features\": meta_features_names,\n",
    "        \"meta_embedding_projections\": projections_maps.get('meta_embedding_projections'),\n",
    "        \"encoder_type\": transactions_model_encoder_type,\n",
    "        \"head_type\": transactions_model_head_type,\n",
    "        \"embedding_dropout\": 0.1\n",
    "    }\n",
    "    transactions_model = TransactionsModel(**transactions_model_config)\n",
    "\n",
    "    return transactions_model, projections_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f695e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_language_model(language_model_name_or_path=\"google/flan-t5-small\"):\n",
    "    use_fast_tokenizer = True\n",
    "\n",
    "    print(f\"Loading Language model: `{language_model_name_or_path}`...\")\n",
    "    config_kwargs = {\n",
    "        \"use_auth_token\": None,\n",
    "        \"return_unused_kwargs\": True\n",
    "    }\n",
    "\n",
    "    tokenizer_kwargs = {\n",
    "        \"use_fast\": use_fast_tokenizer,\n",
    "        \"use_auth_token\": None,\n",
    "        \"do_lowercase\": False\n",
    "    }\n",
    "\n",
    "    config, unused_kwargs = AutoConfig.from_pretrained(\n",
    "        language_model_name_or_path, **config_kwargs\n",
    "    )\n",
    "    # Download vocabulary from huggingface.co and define model-specific arguments\n",
    "    tokenizer = AutoTokenizer.from_pretrained(language_model_name_or_path, **tokenizer_kwargs)\n",
    "\n",
    "    # Download model from huggingface.co and cache.\n",
    "    lm_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        language_model_name_or_path,\n",
    "        config=config\n",
    "    )\n",
    "    return lm_model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb23967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datamodule():\n",
    "    DATA_PATH = '/home/jovyan/romashka/data' \n",
    "    dataset_config = {\n",
    "                'data_dir': DATA_PATH,\n",
    "                'batch_size': 32,\n",
    "                'min_seq_len': 0,\n",
    "                'max_seq_len': 250,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 5,\n",
    "                'pin_memory': True,\n",
    "                'seed': 42\n",
    "    }    \n",
    "\n",
    "    dm = AlfaDataModule(**dataset_config)\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "875247dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tasks(task_names, tokenizer):\n",
    "    # Create tasks\n",
    "    tasks = []\n",
    "    task_kwargs = [{\"num_options\": 6 }] # ground truth + 5 additional options\n",
    "    if isinstance(task_names, str):\n",
    "        task_names = eval(task_names)\n",
    "    task_kwargs = task_kwargs\n",
    "    if isinstance(task_kwargs, str):\n",
    "        task_kwargs = eval(task_kwargs)\n",
    "    print(f\"Got task_names: {task_names} with task_kwargs: {task_kwargs}\")\n",
    "\n",
    "    for task_i, task_name in enumerate(task_names):\n",
    "        task_kwargs = task_kwargs[task_i] if task_i < len(task_kwargs) else {}\n",
    "        if \"tokenizer\" not in task_kwargs:\n",
    "            task_kwargs['tokenizer'] = tokenizer\n",
    "        task_kwargs['use_numerical'] = True    \n",
    "        task = AutoTask.get(task_name=task_name, **task_kwargs)\n",
    "        tasks.append(task)\n",
    "    print(f\"Created {len(tasks)} tasks.\")\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e77a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tqa_model(lm_model, transactions_model, tokenizer, tasks):\n",
    "    # Create general Tranactions QA model\n",
    "    max_steps = 100_000\n",
    "    warmup_steps = 1000\n",
    "    do_freeze_transactions_model = True\n",
    "    do_freeze_language_model = True\n",
    "    do_freeze_connector = False\n",
    "\n",
    "    transactionsQA_model_config = {\n",
    "        \"warmup_steps\": warmup_steps,\n",
    "        \"training_steps\": max_steps,\n",
    "        \"do_freeze_tm\": do_freeze_transactions_model,\n",
    "        \"do_freeze_lm\": do_freeze_language_model,\n",
    "        \"do_freeze_connector\": do_freeze_connector,\n",
    "        \"connector_input_size\": 384,\n",
    "        \"use_numerical\": True\n",
    "    }\n",
    "\n",
    "    model = TransactionQAModel(\n",
    "        language_model=lm_model,\n",
    "        transaction_model=transactions_model,\n",
    "        tokenizer=tokenizer,\n",
    "        tasks=tasks,\n",
    "        **transactionsQA_model_config\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46cc9a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Language model: `google/flan-t5-small`...\n",
      "Loading Transactions model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 14:34:13,559 - [INFO] - Tasks - (task_abstract.py).extend_vocabulary(170) - Added to tokenizer: 3 tokens.\n",
      "2023-05-21 14:34:13,561 - [INFO] - Tasks - (task_abstract.py).extend_vocabulary(176) - Notice: resize_token_embeddings of a model to adapt to the size of the new vocabulary!\n",
      "2023-05-21 14:34:13,572 - [INFO] - TransactionQAModel - (tqa_model.py).__init__(73) - Setuping metrics.\n",
      "2023-05-21 14:34:13,572 - [INFO] - TransactionQAModel - (tqa_model.py).__init__(73) - Setuping metrics.\n",
      "2023-05-21 14:34:13,572 - [INFO] - TransactionQAModel - (tqa_model.py).__init__(73) - Setuping metrics.\n",
      "2023-05-21 14:34:13,577 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(166) - Running in `single task` settingwith a single task: next_amnt_open_ended provided.\n",
      "2023-05-21 14:34:13,577 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(166) - Running in `single task` settingwith a single task: next_amnt_open_ended provided.\n",
      "2023-05-21 14:34:13,577 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(166) - Running in `single task` settingwith a single task: next_amnt_open_ended provided.\n",
      "2023-05-21 14:34:13,579 - [INFO] - TransactionQAModel - (tqa_model.py)._set_model_type(201) - Language model type: `encoder-decoder`\n",
      "2023-05-21 14:34:13,579 - [INFO] - TransactionQAModel - (tqa_model.py)._set_model_type(201) - Language model type: `encoder-decoder`\n",
      "2023-05-21 14:34:13,579 - [INFO] - TransactionQAModel - (tqa_model.py)._set_model_type(201) - Language model type: `encoder-decoder`\n",
      "2023-05-21 14:34:13,581 - [INFO] - TransactionQAModel - (tqa_model.py)._resize_text_embeddings(211) - LM initial `num_embeddings`: 32128, `embedding_dim`: 512\n",
      "2023-05-21 14:34:13,581 - [INFO] - TransactionQAModel - (tqa_model.py)._resize_text_embeddings(211) - LM initial `num_embeddings`: 32128, `embedding_dim`: 512\n",
      "2023-05-21 14:34:13,581 - [INFO] - TransactionQAModel - (tqa_model.py)._resize_text_embeddings(211) - LM initial `num_embeddings`: 32128, `embedding_dim`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING whisper\n",
      "Got task_names: ['next_amnt_open_ended'] with task_kwargs: [{'num_options': 6}]\n",
      "Created 1 tasks.\n",
      "Output dimension of embedding model: 384\n",
      "Input dimension of autoregressive model: 512\n",
      "Creating linear connector from 384 to 512 and move to device: cpu.\n",
      "ModuleDict(\n",
      "  (next_amnt_open_ended): ModuleDict(\n",
      "    (mae): MeanAbsoluteError()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 14:34:13,805 - [INFO] - TransactionQAModel - (tqa_model.py)._resize_text_embeddings(223) - LM resized `num_embeddings`: 32103, `embedding_dim`: 512\n",
      "2023-05-21 14:34:13,805 - [INFO] - TransactionQAModel - (tqa_model.py)._resize_text_embeddings(223) - LM resized `num_embeddings`: 32103, `embedding_dim`: 512\n",
      "2023-05-21 14:34:13,805 - [INFO] - TransactionQAModel - (tqa_model.py)._resize_text_embeddings(223) - LM resized `num_embeddings`: 32103, `embedding_dim`: 512\n",
      "2023-05-21 14:34:13,811 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(177) - Freezing transaction model's parameters...\n",
      "2023-05-21 14:34:13,811 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(177) - Freezing transaction model's parameters...\n",
      "2023-05-21 14:34:13,811 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(177) - Freezing transaction model's parameters...\n",
      "2023-05-21 14:34:13,813 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(182) - Freezing language model's parameters...\n",
      "2023-05-21 14:34:13,813 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(182) - Freezing language model's parameters...\n",
      "2023-05-21 14:34:13,813 - [INFO] - TransactionQAModel - (tqa_model.py)._prepare_model(182) - Freezing language model's parameters...\n"
     ]
    }
   ],
   "source": [
    "task_names = ['next_amnt_open_ended']\n",
    "LM_NAME = 'google/flan-t5-small'\n",
    "\n",
    "lm_model, tokenizer = load_language_model(language_model_name_or_path=LM_NAME)\n",
    "transactions_model, projections_maps = load_transaction_model()\n",
    "\n",
    "tasks = load_tasks(task_names, tokenizer)\n",
    "dm = load_datamodule()\n",
    "\n",
    "tqa_model = make_tqa_model(lm_model, transactions_model, tokenizer, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa325b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9467de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('/home/jovyan/romashka/checkpoints/checkpoints/tqa_200k-steps_ft=all_numerical_next_amnt_open_ended_flan-t5-small_v8/last.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8913896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqa_model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b60fde4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dm.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "833f58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tqa_model.model_step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8e41162",
   "metadata": {},
   "outputs": [],
   "source": [
    "mantissa = res[0]['mantissa']\n",
    "exponent = res[0]['exponent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a54cfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tasks[0].calculate_metrics(res[0], res[1], tqa_model.val_metrics[tasks[0].task_name], stage='val_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73c2888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targets = tasks[0].process_num_outputs(res[0], res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6d42c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0516, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqa_model.val_metrics[tasks[0].task_name]['mae'](preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9fd30a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targets = tqa_model.tasks[0].process_outputs(res[0], res[1])\n",
    "\n",
    "\n",
    "# if 'accuracy' in task_metrics:\n",
    "#     task_metrics['accuracy'](preds, targets)\n",
    "#     metrics[self.task_name + '_accuracy'] = task_metrics['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a21846a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqa_model.tasks[0].metrics['accuracy'](preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "375231e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = torch.load('/home/jovyan/checkpoints/checkpoints/tqa_flan-t5-base_300k-steps_default-binary/last.ckpt')\n",
    "# tqa_model.load_state_dict(ckpt['state_dict'])\n",
    "# tqa_model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50e6b8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08a97055",
   "metadata": {},
   "source": [
    "### AUC, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40f7bc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a546e562934054a35853173186806f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind_pos = tqa_model.tokenizer(\"Yes\").input_ids[0]\n",
    "ind_neg = tqa_model.tokenizer(\"No\").input_ids[0]\n",
    "\n",
    "list_targets = []\n",
    "list_preds = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dm.val_dataloader()):\n",
    "        tqa_model.eval()\n",
    "        cuda_batch = {k: v.to(device='cuda', non_blocking=True) for k, v in batch.items()}\n",
    "        outputs, answers = tqa_model.model_step(cuda_batch)\n",
    "\n",
    "        targets = (answers[:, -2] == ind_pos).long()\n",
    "        preds = torch.sigmoid(outputs.logits[:, 0, ind_pos] - outputs.logits[:, 0, ind_neg])\n",
    "\n",
    "        list_targets.extend(targets.tolist())\n",
    "        list_preds.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3bb748",
   "metadata": {},
   "source": [
    "### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d30d778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "769a7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_preds =list(map(lambda x: int(x>0.5), list_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ff15524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7496266470785984"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(list_targets, list_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83462aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9725179756637168"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(list_targets, hard_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551f8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6038d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee5516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(10) * 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "838eca21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0', '3.5', '7.0', '10.5', '14.0', '17.5', '21.0', '24.5', '28.0', '31.5']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: str(round(x.item(), 2)),t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f6768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ff2a09b934b25be9a8b176e9d1e80ece927d491d3847c62b1a0ae23e4142515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
