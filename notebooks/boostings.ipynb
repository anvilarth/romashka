{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import tqdm\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm\n",
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.transactions_qa.tqa_model import TransactionQAModel\n",
    "from src.models.components.models import TransactionsModel\n",
    "from src.utils.tools import (make_time_batch, \n",
    "                   calculate_embedding_size)\n",
    "\n",
    "from src.data.alfa.components import ( \n",
    "                             cat_features_names, \n",
    "                             num_features_names, \n",
    "                             meta_features_names)\n",
    "\n",
    "from src.data import AlfaDataModule \n",
    "from src.transactions_qa.tqa_model import TransactionQAModel\n",
    "from src.transactions_qa.utils import get_projections_maps, get_exponent_number, get_mantissa_number\n",
    "from src.tasks import AbstractTask, AutoTask\n",
    "from src.transactions_qa.utils import get_split_indices,  prepare_splitted_batch, collate_batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transaction_model(encoder_type='whisper/tiny', head_type='next'):\n",
    "    projections_maps = get_projections_maps(relative_folder=\"..\")\n",
    "    # Loading Transactions model & weights\n",
    "    print(f\"Loading Transactions model...\")\n",
    "\n",
    "    transactions_model_encoder_type = encoder_type\n",
    "    transactions_model_head_type = head_type\n",
    "\n",
    "\n",
    "    transactions_model_config = {\n",
    "        \"cat_features\": cat_features_names,\n",
    "        \"cat_embedding_projections\": projections_maps.get('cat_embedding_projections'),\n",
    "        \"num_features\": num_features_names,\n",
    "        \"num_embedding_projections\": projections_maps.get('num_embedding_projections'),\n",
    "        \"meta_features\": meta_features_names,\n",
    "        \"meta_embedding_projections\": projections_maps.get('meta_embedding_projections'),\n",
    "        \"encoder_type\": transactions_model_encoder_type,\n",
    "        \"head_type\": transactions_model_head_type,\n",
    "        \"embedding_dropout\": 0.1\n",
    "    }\n",
    "    transactions_model = TransactionsModel(**transactions_model_config)\n",
    "\n",
    "    return transactions_model, projections_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datamodule():\n",
    "    DATA_PATH = '/home/jovyan/romashka/data' \n",
    "    dataset_config = {\n",
    "                'data_dir': DATA_PATH,\n",
    "                'batch_size': 32,\n",
    "                'min_seq_len': 0,\n",
    "                'max_seq_len': 250,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 5,\n",
    "                'pin_memory': True,\n",
    "                'seed': 42\n",
    "    }    \n",
    "\n",
    "    dm = AlfaDataModule(**dataset_config)\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tasks(task_names, tokenizer):\n",
    "    # Create tasks\n",
    "    tasks = []\n",
    "    tasks_kwargs = [{\"num_options\": 6, \"floating_threshold\": False, 'answer2text': True, 'use_numerical_output': False}, \n",
    "    {\"num_options\": 6, \"floating_threshold\": False, 'use_numerical_output': False}] # ground truth + 5 additional options\n",
    "    if isinstance(task_names, str):\n",
    "        task_names = eval(task_names)\n",
    "    if isinstance(tasks_kwargs, str):\n",
    "        tasks_kwargs = eval(tasks_kwargs)\n",
    "    print(f\"Got task_names: {task_names} with task_kwargs: {tasks_kwargs}\")\n",
    "\n",
    "    for task_i, task_name in enumerate(task_names):\n",
    "        task_kwargs = tasks_kwargs[task_i] if task_i < len(tasks_kwargs) else {}\n",
    "        if \"tokenizer\" not in task_kwargs:\n",
    "            task_kwargs['tokenizer'] = tokenizer\n",
    "        task = AutoTask.get(task_name=task_name, **task_kwargs)\n",
    "        tasks.append(task)\n",
    "    print(f\"Created {len(tasks)} tasks.\")\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_language_model(language_model_name_or_path=\"google/flan-t5-small\"):\n",
    "    use_fast_tokenizer = True\n",
    "\n",
    "    print(f\"Loading Language model: `{language_model_name_or_path}`...\")\n",
    "    config_kwargs = {\n",
    "        \"use_auth_token\": None,\n",
    "        \"return_unused_kwargs\": True\n",
    "    }\n",
    "\n",
    "    tokenizer_kwargs = {\n",
    "        \"use_fast\": use_fast_tokenizer,\n",
    "        \"use_auth_token\": None,\n",
    "        \"do_lowercase\": False\n",
    "    }\n",
    "\n",
    "    config, unused_kwargs = AutoConfig.from_pretrained(\n",
    "        language_model_name_or_path, **config_kwargs\n",
    "    )\n",
    "    # Download vocabulary from huggingface.co and define model-specific arguments\n",
    "    tokenizer = AutoTokenizer.from_pretrained(language_model_name_or_path, **tokenizer_kwargs)\n",
    "\n",
    "    # Download model from huggingface.co and cache.\n",
    "    lm_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        language_model_name_or_path,\n",
    "        config=config\n",
    "    )\n",
    "    return lm_model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Transactions model...\n",
      "USING whisper\n",
      "Loading Language model: `google/flan-t5-small`...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 17:25:12,323 - [INFO] - Tasks - (task_abstract.py).generate_question_templates(206) - Given 5 starting options and 1 ending options results in 5 total combinations.\n",
      "2023-06-19 17:25:12,325 - [INFO] - Tasks - (task_abstract.py).extend_vocabulary(173) - Added to tokenizer: 2 tokens.\n",
      "2023-06-19 17:25:12,326 - [INFO] - Tasks - (task_abstract.py).extend_vocabulary(179) - Notice: resize_token_embeddings of a model to adapt to the size of the new vocabulary!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got task_names: ['next_amnt_open_ended'] with task_kwargs: [{'num_options': 6, 'floating_threshold': False, 'answer2text': True, 'use_numerical_output': False}, {'num_options': 6, 'floating_threshold': False, 'use_numerical_output': False}]\n",
      "Created 1 tasks.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "task_names = ['next_amnt_open_ended']\n",
    "LM_NAME = 'google/flan-t5-small'\n",
    "\n",
    "transactions_model, projections_maps = load_transaction_model()\n",
    "dm = load_datamodule()\n",
    "\n",
    "lm_model, tokenizer = load_language_model(language_model_name_or_path=LM_NAME)\n",
    "\n",
    "ckpt = torch.load(\"/home/jovyan/checkpoints/transactions_model/final_model_v2.ckpt\", map_location='cpu')\n",
    "transactions_model.load_state_dict(ckpt, strict=False)\n",
    "transactions_model = transactions_model.to(device)\n",
    "\n",
    "\n",
    "tasks = load_tasks(task_names, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16315it [02:29, 109.48it/s]\n",
      "1811it [00:15, 114.05it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(dm.train_dataloader()):\n",
    "        \n",
    "        for key in batch:\n",
    "            batch[key] = batch[key].to(device)\n",
    "\n",
    "        batch_size = batch['mask'].shape[0]\n",
    "        transactions_model.eval()\n",
    "        new_batch = tasks[0].prepare_task_batch(batch)\n",
    "        embs, mask = transactions_model.get_embs(new_batch)\n",
    "        trx_index = mask.sum(1) - 1\n",
    "        train_data.append(embs[torch.arange(batch_size, device=device), trx_index])\n",
    "        train_labels.append(new_batch['label'])\n",
    "    \n",
    "    for batch in tqdm.tqdm(dm.val_dataloader()):\n",
    "        for key in batch:\n",
    "            batch[key] = batch[key].to(device)\n",
    "        \n",
    "        batch_size = batch['mask'].shape[0]\n",
    "        transactions_model.eval()\n",
    "        new_batch = tasks[0].prepare_task_batch(batch)\n",
    "        embs, mask = transactions_model.get_embs(new_batch)\n",
    "        trx_index = mask.sum(1) - 1\n",
    "        val_data.append(embs[torch.arange(batch_size, device=device), trx_index])\n",
    "        val_labels.append(new_batch['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeds = torch.vstack(train_data).cpu().numpy()\n",
    "train_labels = torch.cat(train_labels).cpu().numpy()\n",
    "\n",
    "val_embeds = torch.vstack(val_data).cpu().numpy()\n",
    "val_labels = torch.cat(val_labels).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, metrics, cv, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dataset = Pool(data=train_embeds,\n",
    "                  label=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/2]\n",
      "\n",
      "bestTest = 0.08435387037\n",
      "bestIteration = 99\n",
      "\n",
      "Training on fold [1/2]\n",
      "\n",
      "bestTest = 0.08446942171\n",
      "bestIteration = 99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\"iterations\": 100,\n",
    "          \"depth\": 2,\n",
    "          \"loss_function\": \"MAE\",\n",
    "          \"verbose\": False}\n",
    "\n",
    "scores = cv(cv_dataset,\n",
    "            params,\n",
    "            fold_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-MAE-mean</th>\n",
       "      <th>test-MAE-std</th>\n",
       "      <th>train-MAE-mean</th>\n",
       "      <th>train-MAE-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.385173</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.385172</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.373607</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.362380</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.362380</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.351625</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.351624</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.084945</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.084931</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0.084805</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.084790</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.084663</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.084649</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.084539</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.084524</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.084412</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.084397</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  test-MAE-mean  test-MAE-std  train-MAE-mean  train-MAE-std\n",
       "0            0       0.397069      0.000076        0.397069       0.000085\n",
       "1            1       0.385173      0.000077        0.385172       0.000080\n",
       "2            2       0.373608      0.000081        0.373607       0.000076\n",
       "3            3       0.362380      0.000150        0.362380       0.000141\n",
       "4            4       0.351625      0.000149        0.351624       0.000135\n",
       "..         ...            ...           ...             ...            ...\n",
       "95          95       0.084945      0.000080        0.084931       0.000004\n",
       "96          96       0.084805      0.000075        0.084790       0.000010\n",
       "97          97       0.084663      0.000074        0.084649       0.000012\n",
       "98          98       0.084539      0.000081        0.084524       0.000008\n",
       "99          99       0.084412      0.000082        0.084397       0.000010\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoostModel_emb = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    custom_metric=[metrics.MAE()],\n",
    "    random_seed=42,\n",
    "    depth=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoostModel_emb.fit(\n",
    "    train_embeds, train_labels,\n",
    "    plot=True,\n",
    "    logging_level='Verbose',  # you can uncomment this for text output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(train_embeds, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23643428, 0.23822398, 0.23560267, 0.23263571, 0.23815126])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lm, train_embeds, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_embeds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_170353/459733004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_embeds' is not defined"
     ]
    }
   ],
   "source": [
    "val_pred = lm.predict(val_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_170353/184993640.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_pred' is not defined"
     ]
    }
   ],
   "source": [
    "mean_absolute_error(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = RandomForestRegressor(n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_embeds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_170353/587316545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_embeds' is not defined"
     ]
    }
   ],
   "source": [
    "dtree.fit(train_embeds, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(256, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = np.random.randn(100, 256)\n",
    "y = np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(256, 256, 256))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(batch, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transactions_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_170353/4243794067.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransactions_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'transactions_model' is not defined"
     ]
    }
   ],
   "source": [
    "transactions_model.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ff2a09b934b25be9a8b176e9d1e80ece927d491d3847c62b1a0ae23e4142515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
