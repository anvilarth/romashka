{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import tqdm\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm\n",
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.transactions_qa.tqa_model import TransactionQAModel\n",
    "from src.models.components.models import TransactionsModel\n",
    "from src.utils.tools import (make_time_batch, \n",
    "                   calculate_embedding_size)\n",
    "\n",
    "from src.data.alfa.components import ( \n",
    "                             cat_features_names, \n",
    "                             num_features_names, \n",
    "                             meta_features_names)\n",
    "\n",
    "from src.data import AlfaDataModule \n",
    "from src.transactions_qa.tqa_model import TransactionQAModel\n",
    "from src.transactions_qa.utils import get_projections_maps, get_exponent_number, get_mantissa_number\n",
    "from src.tasks import AbstractTask, AutoTask\n",
    "from src.transactions_qa.utils import get_split_indices,  prepare_splitted_batch, collate_batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transaction_model(encoder_type='whisper/tiny', head_type='next'):\n",
    "    projections_maps = get_projections_maps(relative_folder=\"..\")\n",
    "    # Loading Transactions model & weights\n",
    "    print(f\"Loading Transactions model...\")\n",
    "\n",
    "    transactions_model_encoder_type = encoder_type\n",
    "    transactions_model_head_type = head_type\n",
    "\n",
    "\n",
    "    transactions_model_config = {\n",
    "        \"cat_features\": cat_features_names,\n",
    "        \"cat_embedding_projections\": projections_maps.get('cat_embedding_projections'),\n",
    "        \"num_features\": num_features_names,\n",
    "        \"num_embedding_projections\": projections_maps.get('num_embedding_projections'),\n",
    "        \"meta_features\": meta_features_names,\n",
    "        \"meta_embedding_projections\": projections_maps.get('meta_embedding_projections'),\n",
    "        \"encoder_type\": transactions_model_encoder_type,\n",
    "        \"head_type\": transactions_model_head_type,\n",
    "        \"embedding_dropout\": 0.1\n",
    "    }\n",
    "    transactions_model = TransactionsModel(**transactions_model_config)\n",
    "\n",
    "    return transactions_model, projections_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datamodule():\n",
    "    DATA_PATH = '/home/jovyan/romashka/data' \n",
    "    dataset_config = {\n",
    "                'data_dir': DATA_PATH,\n",
    "                'batch_size': 32,\n",
    "                'min_seq_len': 0,\n",
    "                'max_seq_len': 250,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 5,\n",
    "                'pin_memory': True,\n",
    "                'seed': 42\n",
    "    }    \n",
    "\n",
    "    dm = AlfaDataModule(**dataset_config)\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tasks(task_names, tokenizer):\n",
    "    # Create tasks\n",
    "    tasks = []\n",
    "    tasks_kwargs = [{\"num_options\": 6, \"floating_threshold\": False, 'answer2text': True, 'use_numerical_output': False}, \n",
    "    {\"num_options\": 6, \"floating_threshold\": False, 'use_numerical_output': False}] # ground truth + 5 additional options\n",
    "    if isinstance(task_names, str):\n",
    "        task_names = eval(task_names)\n",
    "    if isinstance(tasks_kwargs, str):\n",
    "        tasks_kwargs = eval(tasks_kwargs)\n",
    "    print(f\"Got task_names: {task_names} with task_kwargs: {tasks_kwargs}\")\n",
    "\n",
    "    for task_i, task_name in enumerate(task_names):\n",
    "        task_kwargs = tasks_kwargs[task_i] if task_i < len(tasks_kwargs) else {}\n",
    "        if \"tokenizer\" not in task_kwargs:\n",
    "            task_kwargs['tokenizer'] = tokenizer\n",
    "        task = AutoTask.get(task_name=task_name, **task_kwargs)\n",
    "        tasks.append(task)\n",
    "    print(f\"Created {len(tasks)} tasks.\")\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_language_model(language_model_name_or_path=\"google/flan-t5-small\"):\n",
    "    use_fast_tokenizer = True\n",
    "\n",
    "    print(f\"Loading Language model: `{language_model_name_or_path}`...\")\n",
    "    config_kwargs = {\n",
    "        \"use_auth_token\": None,\n",
    "        \"return_unused_kwargs\": True\n",
    "    }\n",
    "\n",
    "    tokenizer_kwargs = {\n",
    "        \"use_fast\": use_fast_tokenizer,\n",
    "        \"use_auth_token\": None,\n",
    "        \"do_lowercase\": False\n",
    "    }\n",
    "\n",
    "    config, unused_kwargs = AutoConfig.from_pretrained(\n",
    "        language_model_name_or_path, **config_kwargs\n",
    "    )\n",
    "    # Download vocabulary from huggingface.co and define model-specific arguments\n",
    "    tokenizer = AutoTokenizer.from_pretrained(language_model_name_or_path, **tokenizer_kwargs)\n",
    "\n",
    "    # Download model from huggingface.co and cache.\n",
    "    lm_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        language_model_name_or_path,\n",
    "        config=config\n",
    "    )\n",
    "    return lm_model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Transactions model...\n",
      "USING whisper\n",
      "Loading Language model: `google/flan-t5-small`...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 16:42:14,680 - [INFO] - Tasks - (task_abstract.py).generate_question_templates(206) - Given 5 starting options and 1 ending options results in 5 total combinations.\n",
      "2023-06-25 16:42:14,683 - [INFO] - Tasks - (task_abstract.py).extend_vocabulary(173) - Added to tokenizer: 2 tokens.\n",
      "2023-06-25 16:42:14,684 - [INFO] - Tasks - (task_abstract.py).extend_vocabulary(179) - Notice: resize_token_embeddings of a model to adapt to the size of the new vocabulary!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got task_names: ['next_amnt_open_ended'] with task_kwargs: [{'num_options': 6, 'floating_threshold': False, 'answer2text': True, 'use_numerical_output': False}, {'num_options': 6, 'floating_threshold': False, 'use_numerical_output': False}]\n",
      "Created 1 tasks.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "task_names = ['next_amnt_open_ended']\n",
    "LM_NAME = 'google/flan-t5-small'\n",
    "\n",
    "transactions_model, projections_maps = load_transaction_model()\n",
    "dm = load_datamodule()\n",
    "\n",
    "lm_model, tokenizer = load_language_model(language_model_name_or_path=LM_NAME)\n",
    "\n",
    "ckpt = torch.load(\"/home/jovyan/checkpoints/transactions_model/final_model_v2.ckpt\", map_location='cpu')\n",
    "transactions_model.load_state_dict(ckpt, strict=False)\n",
    "transactions_model = transactions_model.to(device)\n",
    "\n",
    "\n",
    "tasks = load_tasks(task_names, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16315it [04:07, 65.80it/s] \n",
      "1811it [00:21, 85.94it/s] \n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(dm.train_dataloader()):\n",
    "        \n",
    "        for key in batch:\n",
    "            batch[key] = batch[key].to(device)\n",
    "\n",
    "        batch_size = batch['mask'].shape[0]\n",
    "        transactions_model.eval()\n",
    "        new_batch = tasks[0].prepare_task_batch(batch)\n",
    "        embs, mask = transactions_model.get_embs(new_batch)\n",
    "        trx_index = mask.sum(1) - 1\n",
    "        train_data.append(embs[torch.arange(batch_size, device=device), trx_index])\n",
    "        train_labels.append(new_batch['label'])\n",
    "    \n",
    "    for batch in tqdm.tqdm(dm.val_dataloader()):\n",
    "        for key in batch:\n",
    "            batch[key] = batch[key].to(device)\n",
    "        \n",
    "        batch_size = batch['mask'].shape[0]\n",
    "        transactions_model.eval()\n",
    "        new_batch = tasks[0].prepare_task_batch(batch)\n",
    "        embs, mask = transactions_model.get_embs(new_batch)\n",
    "        trx_index = mask.sum(1) - 1\n",
    "        val_data.append(embs[torch.arange(batch_size, device=device), trx_index])\n",
    "        val_labels.append(new_batch['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeds = torch.vstack(train_data).cpu().numpy()\n",
    "train_labels = torch.cat(train_labels).cpu().numpy()\n",
    "\n",
    "val_embeds = torch.vstack(val_data).cpu().numpy()\n",
    "val_labels = torch.cat(val_labels).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/home/jovyan/romashka/assets/boosting_embeds/train_embeds.npy', train_embeds)\n",
    "# np.save('/home/jovyan/romashka/assets/boosting_embeds/val_embeds.npy', val_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, metrics, cv, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m0.0104\u001b[0m        \u001b[32m0.0095\u001b[0m  253.3617\n",
      "      4        \u001b[36m0.0104\u001b[0m        \u001b[32m0.0096\u001b[0m  255.8253\n",
      "      3        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0104\u001b[0m  400.7570\n",
      "      3        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0105\u001b[0m  392.0843\n",
      "      3        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0103\u001b[0m  402.2128\n",
      "      3        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0103\u001b[0m  405.7684\n",
      "      3        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0102\u001b[0m  403.0029\n",
      "      3        \u001b[36m0.0100\u001b[0m        \u001b[32m0.0104\u001b[0m  407.7536\n",
      "      3        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0102\u001b[0m  412.7552\n",
      "      3        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0102\u001b[0m  404.5129\n",
      "      3        \u001b[36m0.0100\u001b[0m        \u001b[32m0.0103\u001b[0m  409.5076\n",
      "      3        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0102\u001b[0m  410.9874\n",
      "      5        \u001b[36m0.0104\u001b[0m        \u001b[32m0.0094\u001b[0m  250.6669\n",
      "      5        \u001b[36m0.0103\u001b[0m        \u001b[32m0.0095\u001b[0m  251.5339\n",
      "      6        \u001b[36m0.0103\u001b[0m        \u001b[32m0.0095\u001b[0m  244.7502\n",
      "      6        \u001b[36m0.0103\u001b[0m        \u001b[32m0.0093\u001b[0m  252.2118\n",
      "      4        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0103\u001b[0m  395.9808\n",
      "      4        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0104\u001b[0m  390.6588\n",
      "      4        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0102\u001b[0m  406.8379\n",
      "      4        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0101\u001b[0m  385.0801\n",
      "      4        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0102\u001b[0m  403.4823\n",
      "      4        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0103\u001b[0m  397.6025\n",
      "      4        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  400.2615\n",
      "      4        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  399.3349\n",
      "      4        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0102\u001b[0m  395.7941\n",
      "      4        \u001b[36m0.0099\u001b[0m        \u001b[32m0.0101\u001b[0m  408.3665\n",
      "      7        \u001b[36m0.0103\u001b[0m        \u001b[32m0.0094\u001b[0m  250.7566\n",
      "      7        \u001b[36m0.0103\u001b[0m        \u001b[32m0.0093\u001b[0m  250.8808\n",
      "      5        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0103\u001b[0m  390.0970\n",
      "      5        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0102\u001b[0m  403.1495\n",
      "      5        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0102\u001b[0m  393.2487\n",
      "      5        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0102\u001b[0m  401.5251\n",
      "      5        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  397.6435\n",
      "      5        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  404.1528\n",
      "      5        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  395.7454\n",
      "      5        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  409.0755\n",
      "      5        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  404.8215\n",
      "      5        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  411.5834\n",
      "      8        \u001b[36m0.0102\u001b[0m        \u001b[32m0.0093\u001b[0m  246.6533\n",
      "      8        \u001b[36m0.0102\u001b[0m        \u001b[32m0.0094\u001b[0m  255.8137\n",
      "      9        \u001b[36m0.0102\u001b[0m        \u001b[32m0.0092\u001b[0m  250.4073\n",
      "      9        \u001b[36m0.0102\u001b[0m        \u001b[32m0.0093\u001b[0m  254.7742\n",
      "      6        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0102\u001b[0m  393.0496\n",
      "      6        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  400.2463\n",
      "      6        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0102\u001b[0m  392.4187\n",
      "      6        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0100\u001b[0m  396.7912\n",
      "      6        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  403.8059\n",
      "      6        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  402.7603\n",
      "      6        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  399.1653\n",
      "      6        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  406.7222\n",
      "      6        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0101\u001b[0m  402.3396\n",
      "      6        \u001b[36m0.0098\u001b[0m        \u001b[32m0.0100\u001b[0m  399.1970\n"
     ]
    }
   ],
   "source": [
    "class MyCatBoost(CatBoostRegressor, BaseEstimator):\n",
    "    def __init__(self, random_state=0):\n",
    "        super().__init__()\n",
    "        self.random_state = random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_dataset = Pool(data=train_embeds,\n",
    "#                   label=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\"iterations\": 100,\n",
    "#           \"depth\": 2,\n",
    "#           \"loss_function\": \"MAE\",\n",
    "#           \"verbose\": False}\n",
    "\n",
    "# scores = cv(cv_dataset,\n",
    "#             params,\n",
    "#             fold_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-MAE-mean</th>\n",
       "      <th>test-MAE-std</th>\n",
       "      <th>train-MAE-mean</th>\n",
       "      <th>train-MAE-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.385173</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.385172</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.373607</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.362380</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.362380</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.351625</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.351624</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.084945</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.084931</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0.084805</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.084790</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.084663</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.084649</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.084539</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.084524</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.084412</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.084397</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  test-MAE-mean  test-MAE-std  train-MAE-mean  train-MAE-std\n",
       "0            0       0.397069      0.000076        0.397069       0.000085\n",
       "1            1       0.385173      0.000077        0.385172       0.000080\n",
       "2            2       0.373608      0.000081        0.373607       0.000076\n",
       "3            3       0.362380      0.000150        0.362380       0.000141\n",
       "4            4       0.351625      0.000149        0.351624       0.000135\n",
       "..         ...            ...           ...             ...            ...\n",
       "95          95       0.084945      0.000080        0.084931       0.000004\n",
       "96          96       0.084805      0.000075        0.084790       0.000010\n",
       "97          97       0.084663      0.000074        0.084649       0.000012\n",
       "98          98       0.084539      0.000081        0.084524       0.000008\n",
       "99          99       0.084412      0.000082        0.084397       0.000010\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoostModel_emb = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    custom_metric=[metrics.MAE()],\n",
    "    random_seed=42,\n",
    "    depth=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoostModel_emb.fit(\n",
    "    train_embeds, train_labels,\n",
    "    plot=True,\n",
    "    logging_level='Verbose',  # you can uncomment this for text output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-22 12:56:25,194]\u001b[0m Trial 4 finished with value: -0.06621766998259493 and parameters: {'n_estimators': 191, 'max_depth': 14, 'min_samples_split': 41, 'min_samples_leaf': 47}. Best is trial 4 with value: -0.06621766998259493.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# model = LinearRegression(n_jobs=-1)\n",
    "model = Ridge()\n",
    "model_params = {'alpha': optuna.distributions.UniformDistribution(low=0.1, high=100)}\n",
    "\n",
    "# model = MLPRegressor(hidden_layer_sizes=(256, 256, 256))\n",
    "\n",
    "model = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "model_params = {\n",
    "    'n_estimators': optuna.distributions.IntUniformDistribution(50, 1000),\n",
    "    'max_depth':  optuna.distributions.IntUniformDistribution(4, 50),\n",
    "    'min_samples_split': optuna.distributions.IntUniformDistribution(1, 150),\n",
    "    'min_samples_leaf':  optuna.distributions.IntUniformDistribution(1, 60),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "\u001b[32m[I 2023-06-22 13:06:10,829]\u001b[0m A new study created in memory with name: no-name-4f04d92f-6666-4d10-aee4-80c4bf17b6fa\u001b[0m\n",
      "/home/user/conda/lib/python3.7/site-packages/optuna/study/study.py:397: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.\n",
      "  FutureWarning,\n",
      "\u001b[32m[I 2023-06-22 13:06:20,561]\u001b[0m Trial 1 finished with value: -0.06682577887790586 and parameters: {'n_estimators': 830, 'max_depth': 35, 'min_samples_split': 105, 'min_samples_leaf': 26}. Best is trial 1 with value: -0.06682577887790586.\u001b[0m\n",
      "\u001b[32m[I 2023-06-22 13:06:20,596]\u001b[0m Trial 0 finished with value: -0.06801305764369374 and parameters: {'n_estimators': 961, 'max_depth': 19, 'min_samples_split': 100, 'min_samples_leaf': 10}. Best is trial 1 with value: -0.06682577887790586.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from optuna.integration import OptunaSearchCV\n",
    "\n",
    "optuna_search = OptunaSearchCV(model, model_params, cv=5, n_jobs=-1, n_trials=2)\n",
    "\n",
    "optuna_search.fit(train_embeds[:100], train_labels[:100])\n",
    "y_pred = optuna_search.predict(val_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09486297043245859"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_embeds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_170353/459733004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_embeds' is not defined"
     ]
    }
   ],
   "source": [
    "# lm.fit(train_embeds, train_labels)\n",
    "# val_pred = model.predict(val_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skorch\n",
      "  Downloading skorch-0.13.0-py3-none-any.whl (209 kB)\n",
      "     |████████████████████████████████| 209 kB 2.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /home/user/conda/lib/python3.7/site-packages (from skorch) (0.8.9)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /home/user/conda/lib/python3.7/site-packages (from skorch) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/user/conda/lib/python3.7/site-packages (from skorch) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/user/conda/lib/python3.7/site-packages (from skorch) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.14.0 in /home/user/conda/lib/python3.7/site-packages (from skorch) (4.62.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/user/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.0->skorch) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.0->skorch) (3.0.0)\n",
      "Installing collected packages: skorch\n",
      "Successfully installed skorch-0.13.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "\n",
    "from skorch import NeuralNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            inp_size,\n",
    "            hidden_size,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.inp_size = inp_size\n",
    "        self.nonlin = nonlin\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.linear1 = nn.Linear(inp_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = self.linear2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_nn = partial(SimpleMLP, inp_size=train_embeds.shape[1])\n",
    "\n",
    "model_params = {'module__hidden_size': optuna.distributions.IntUniformDistribution(10, 150)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetRegressor( \n",
    "    SimpleMLP,\n",
    "    max_epochs=20,\n",
    "    module__hidden_size=10,\n",
    "    module__inp_size=384,\n",
    "    lr=0.1,\n",
    "    device='cuda',\n",
    "      # uncomment this to train with CUDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_search = optuna.integration.OptunaSearchCV(net, model_params, cv=2, n_jobs=-1, n_trials=2, verbose=1)\n",
    "optuna_search.fit(train_embeds[:100], train_labels[:100].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m0.0103\u001b[0m        \u001b[32m0.0095\u001b[0m  7.9826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=SimpleMLP(\n",
       "    (linear1): Linear(in_features=384, out_features=10, bias=True)\n",
       "    (linear2): Linear(in_features=10, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net.fit(train_embeds, train_labels.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ff2a09b934b25be9a8b176e9d1e80ece927d491d3847c62b1a0ae23e4142515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
