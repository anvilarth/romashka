{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvasilev-va\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/jovyan/v_vasilev/romashka/wandb/run-20230208_221108-dqvs6bqu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mptls-mlm-rnn-splits=5-seqlen=200-bs=64\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vasilev-va/romashka\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vasilev-va/romashka/runs/dqvs6bqu\u001b[0m\n",
      "Splitter is None.\n",
      "The mode is MLM. Param hidden_size was assigned to output_size of trx_encoder: 182\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type               | Params\n",
      "-------------------------------------------------------\n",
      "0 | trx_encoder     | PtlsEmbeddingLayer | 14.1 K\n",
      "1 | _seq_encoder    | RnnEncoder         | 200 K \n",
      "2 | fn_norm_predict | PBShell            | 0     \n",
      "3 | loss_fn         | QuerySoftmaxLoss   | 0     \n",
      "4 | train_mlm_loss  | MeanMetric         | 0     \n",
      "5 | valid_mlm_loss  | MeanMetric         | 0     \n",
      "-------------------------------------------------------\n",
      "214 K     Trainable params\n",
      "0         Non-trainable params\n",
      "214 K     Total params\n",
      "0.857     Total estimated model params size (MB)\n",
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 255 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "Epoch 0: : 135it [00:07, 17.51it/s, loss=1.83, v_num=6bqu]^C\n",
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "Traceback (most recent call last):\n",
      "  File \"ptls_run.py\", line 199, in <module>\n",
      "    torch.save(model.state_dict(), args.checkpoint_dir + '/ptls_ckpts/' + run_name + '-final.ckpt')\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/torch/serialization.py\", line 376, in save\n",
      "    with _open_file_like(f, 'wb') as opened_file:\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/jovyan/v_vasilev/checkpoints/ptls_ckpts/ptls-mlm-rnn-splits=5-seqlen=200-bs=64-final.ckpt'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python ptls_run.py --group coles --splitter slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch \n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from models import TransactionsModel\n",
    "from data_generators import batches_generator, cat_features_names, num_features_names, meta_features_names\n",
    "\n",
    "from embedding import EmbeddingLayer\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.frames.bert import MLMPretrainModule\n",
    "\n",
    "from ptls.nn import RnnSeqEncoder\n",
    "from ptls.nn import TransformerEncoder\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./assets/num_embedding_projections.pkl', 'rb') as f:\n",
    "    num_embedding_projections = pickle.load(f)\n",
    "    \n",
    "with open('./assets/cat_embedding_projections.pkl', 'rb') as f:\n",
    "    cat_embedding_projections = pickle.load(f)\n",
    "\n",
    "with open('./assets/meta_embedding_projections.pkl', 'rb') as f:\n",
    "    meta_embedding_projections = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddedBatch:\n",
    "    def __init__(self, data, mask):\n",
    "        self.payload = data\n",
    "        self.seq_lens = torch.LongTensor([data.shape[1]] * data.shape[0]).to(device)\n",
    "        self.seq_len_mask = mask\n",
    "        \n",
    "class IterDataset(IterableDataset):\n",
    "    def __init__(self, dataset_train, batch_size=64, device='cuda'):\n",
    "        self.data = dataset_train\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.foo = lambda: batches_generator(self.data, batch_size=self.batch_size, shuffle=True, device=self.device, is_train=True, output_format='torch', min_seq_len=200)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = '/home/jovyan/afilatov/data/alfa/train_buckets'\n",
    "\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_train = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])[0:1]\n",
    "\n",
    "#train_dataloader = batches_generator(dataset_train, batch_size=64, shuffle=True,\n",
    "#                                            device=device, is_train=True, output_format='torch', min_seq_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IterDataset(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PtlsEmbeddingLayer(EmbeddingLayer):\n",
    "    def __init__(self, splitter, *args, **kwargs):\n",
    "        self.splitter = splitter\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.output_size = self.get_embedding_size()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = x['mask']\n",
    "        x = super().forward(x)\n",
    "        return PaddedBatch(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySampleUniform:\n",
    "    \"\"\"\n",
    "    Sub samples with equal length = `seq_len`\n",
    "    Start pos has fixed uniform distribution from sequence start to end with equal step\n",
    "    |---------------------|       main sequence\n",
    "    |------|              |        sub seq 1\n",
    "    |    |------|         |        sub seq 2\n",
    "    |         |------|    |        sub seq 3\n",
    "    |              |------|        sub seq 4\n",
    "    There is no random factor in this splitter, so sub sequences are the same every time\n",
    "    Can be used during inference as test time augmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, split_count, seq_len, **_):\n",
    "        self.split_count = split_count\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def split(self, dates):\n",
    "        date_len = dates.shape[0]\n",
    "        date_range = np.arange(date_len)\n",
    "\n",
    "        if date_len <= self.seq_len + self.split_count:\n",
    "            return [date_range for _ in range(self.split_count)]\n",
    "\n",
    "        start_pos = np.linspace(0, date_len - self.seq_len, self.split_count).round().astype(int)\n",
    "        return [date_range[s:s + self.seq_len] for s in start_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['num_features', 'cat_features', 'mask', 'event_time', 'meta_features', 'label', 'app_id'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def split_process(batch, splitter):\n",
    "    res = {}\n",
    "    \n",
    "    local_date = batch['event_time']\n",
    "    if splitter is not None:\n",
    "        indexes = splitter.split(local_date)\n",
    "        pad_size = max([len(ixs) for ixs in indexes])\n",
    "    \n",
    "    for k, v in batch.items():\n",
    "        if type(v) == list and len(v) > 1 and splitter is not None:\n",
    "            new_v = []\n",
    "            for elem in v:\n",
    "                tmp = []\n",
    "                for i, ixs in enumerate(indexes):\n",
    "                    to_tmp = elem[:, ixs]\n",
    "                    if to_tmp.shape[1] < pad_size:\n",
    "                        to_tmp = torch.cat([\n",
    "                            to_tmp, torch.zeros(to_tmp.shape[0], pad_size - to_tmp.shape[1]).to(device)\n",
    "                        ], axis=1)\n",
    "                    tmp.append(to_tmp)\n",
    "                new_v.append(torch.cat(tmp, dim=0))\n",
    "        else:\n",
    "            new_v = v \n",
    "        res[k] = new_v\n",
    "    return res\n",
    "\n",
    "def replace_token(batch, replace_prob=0.15, skip_first=1):\n",
    "    mask = batch['mask']\n",
    "    to_replace = torch.bernoulli(mask * replace_prob).bool()\n",
    "    to_replace[:, :skip_first] = False\n",
    "\n",
    "    sampled_trx_ids = torch.multinomial(\n",
    "        mask.flatten().float(),\n",
    "        num_samples=to_replace.sum().item(),\n",
    "        replacement=True,\n",
    "    )\n",
    "\n",
    "    to_replace_flatten = to_replace.flatten()\n",
    "    new_x = deepcopy(batch)\n",
    "    for k, v in new_x.items():\n",
    "        if type(v) == list and len(v) > 1:\n",
    "            for elem in v:\n",
    "                elem.flatten()[to_replace_flatten] = elem.flatten()[sampled_trx_ids]\n",
    "    return new_x, to_replace.long().flatten()#[mask.flatten().bool()]\n",
    "\n",
    "\n",
    "def my_collate_fn(batch, splitter, rep=5, mode='coles'):\n",
    "    batch = batch[0]\n",
    "    len_batch = batch['num_features'][0].shape[0]\n",
    "    labels = torch.arange(len_batch).repeat(rep)\n",
    "    batch = split_process(batch, splitter)\n",
    "    \n",
    "    if mode == 'coles':\n",
    "        return batch, labels\n",
    "    \n",
    "    if mode == 'cpc':\n",
    "        return batch, None\n",
    "    \n",
    "    if mode == 'rtd':\n",
    "        batch, labels = replace_token(batch)\n",
    "        return batch, labels\n",
    "        \n",
    "    if mode == 'mlm':\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.frames import PtlsDataModule\n",
    "\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.data_load.utils import collate_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "coles_splitter = MySampleUniform(\n",
    "        split_count=5,\n",
    "        seq_len=100\n",
    "    )\n",
    "coles_splitter = SampleSlices(split_count=5, cnt_min=50, cnt_max=100)\n",
    "\n",
    "coles_ptls_emb_layer = PtlsEmbeddingLayer(coles_splitter,\n",
    "                                    cat_embedding_projections,\n",
    "                                    cat_features_names,\n",
    "                                    num_embedding_projections,\n",
    "                                    num_features_names).cuda()\n",
    "\n",
    "coles_seq_encoder = RnnSeqEncoder(\n",
    "    input_size=coles_ptls_emb_layer.get_embedding_size(),\n",
    "    trx_encoder=coles_ptls_emb_layer,\n",
    "    hidden_size=256,\n",
    "    type='gru',\n",
    ")\n",
    "\n",
    "coles_model = CoLESModule(\n",
    "    seq_encoder=coles_seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9),\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "coles_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=partial(my_collate_fn, splitter=coles_splitter, rep=5, mode='coles'),\n",
    "    num_workers=0,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import logging\n",
    "\n",
    "coles_trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    gpus=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 352 K \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "352 K     Trainable params\n",
      "0         Non-trainable params\n",
      "352 K     Total params\n",
      "1.409     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c85e3ff93fd40649bfc4b0c43317b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %debug\n",
    "coles_trainer.fit(coles_model, coles_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.frames.cpc import CpcModule\n",
    "from ptls.frames.coles.split_strategy import SampleSlices, SampleUniformBySplitCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_splitter = SampleUniformBySplitCount(split_count=5) # splitter should preserve order in samples\n",
    "cpc_splitter = SampleSlices(split_count=5, cnt_min=50, cnt_max=100, is_sorted=True)\n",
    "\n",
    "cpc_ptls_emb_layer = PtlsEmbeddingLayer(cpc_splitter,\n",
    "                                        cat_embedding_projections,\n",
    "                                        cat_features_names,\n",
    "                                        num_embedding_projections,\n",
    "                                        num_features_names).cuda()\n",
    "\n",
    "cpc_seq_encoder = RnnSeqEncoder(\n",
    "    input_size=cpc_ptls_emb_layer.get_embedding_size(),\n",
    "    trx_encoder=cpc_ptls_emb_layer,\n",
    "    hidden_size=256,\n",
    "    type='gru',\n",
    ")\n",
    "\n",
    "cpc_model = CpcModule(\n",
    "    seq_encoder=cpc_seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=partial(my_collate_fn, splitter=cpc_splitter, mode='cpc'),\n",
    "    num_workers=0,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "cpc_trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    gpus=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type          | Params\n",
      "-----------------------------------------------------\n",
      "0 | _loss              | CPC_Loss      | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder | 352 K \n",
      "2 | _validation_metric | CpcAccuracy   | 0     \n",
      "3 | _linears           | ModuleList    | 280 K \n",
      "-----------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.532     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f7447e801e4fc58369c35d4d4fdcdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%debug\n",
    "cpc_trainer.fit(cpc_model, cpc_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from ptls.frames.bert import RtdModule\n",
    "from ptls.nn.seq_encoder.utils import AllStepsHead, FlattenHead\n",
    "from ptls.frames.coles.split_strategy import SampleUniformBySplitCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtd_splitter = SampleUniformBySplitCount(split_count=5)\n",
    "rtd_ptls_emb_layer = PtlsEmbeddingLayer(rtd_splitter,\n",
    "                                        cat_embedding_projections,\n",
    "                                        cat_features_names,\n",
    "                                        num_embedding_projections,\n",
    "                                        num_features_names).cuda()\n",
    "\n",
    "rtd_seq_encoder = RnnSeqEncoder(\n",
    "    input_size=rtd_ptls_emb_layer.get_embedding_size(),\n",
    "    trx_encoder=rtd_ptls_emb_layer,\n",
    "    hidden_size=256,\n",
    "    type='gru',\n",
    ").cuda()\n",
    "\n",
    "rtd_model = RtdModule(\n",
    "    seq_encoder=rtd_seq_encoder,\n",
    "    validation_metric=torchmetrics.AUROC(task='binary'),\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9),\n",
    "    head = torch.nn.Sequential(\n",
    "        AllStepsHead(\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Linear(256, 1),\n",
    "                torch.nn.Sigmoid(),\n",
    "                torch.nn.Flatten(),\n",
    "            )\n",
    "        ),\n",
    "        FlattenHead(),\n",
    "    )\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtd_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=partial(my_collate_fn, splitter=None, mode='rtd', rep=1),\n",
    "    num_workers=0,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "rtd_trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    gpus=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type          | Params\n",
      "-----------------------------------------------------\n",
      "0 | _loss              | BCELoss       | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder | 352 K \n",
      "2 | _validation_metric | BinaryAUROC   | 0     \n",
      "3 | _head              | Sequential    | 257   \n",
      "-----------------------------------------------------\n",
      "352 K     Trainable params\n",
      "0         Non-trainable params\n",
      "352 K     Total params\n",
      "1.410     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b901a45833d438b98b5d71aef6bf83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%debug\n",
    "rtd_trainer.fit(rtd_model, rtd_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.frames.bert import MLMPretrainModule\n",
    "from ptls.nn import RnnEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_ptls_emb_layer = PtlsEmbeddingLayer(None,\n",
    "                                        cat_embedding_projections,\n",
    "                                        cat_features_names,output_size\n",
    "                                        num_embedding_projections,\n",
    "                                        num_features_names).cuda()\n",
    "\n",
    "mlm_seq_encoder = RnnEncoder(\n",
    "    #trx_encoder=mlm_ptls_emb_layer,\n",
    "    input_size=mlm_ptls_emb_layer.get_embedding_size(),\n",
    "    is_reduce_sequence=False,\n",
    "    hidden_size=182,\n",
    "    type='gru',\n",
    ").cuda()\n",
    "\n",
    "mlm_model = MLMPretrainModule(\n",
    "    trx_encoder=mlm_ptls_emb_layer, \n",
    "    seq_encoder=mlm_seq_encoder,\n",
    "    total_steps=10000\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=partial(my_collate_fn, splitter=None, rep=1, mode='mlm'),\n",
    "    num_workers=0,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "mlm_trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    gpus=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type               | Params\n",
      "-------------------------------------------------------\n",
      "0 | trx_encoder     | PtlsEmbeddingLayer | 14.1 K\n",
      "1 | _seq_encoder    | RnnEncoder         | 200 K \n",
      "2 | fn_norm_predict | PBShell            | 0     \n",
      "3 | loss_fn         | QuerySoftmaxLoss   | 0     \n",
      "4 | train_mlm_loss  | MeanMetric         | 0     \n",
      "5 | valid_mlm_loss  | MeanMetric         | 0     \n",
      "-------------------------------------------------------\n",
      "214 K     Trainable params\n",
      "0         Non-trainable params\n",
      "214 K     Total params\n",
      "0.857     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0605ca89657d4303819431cceb028a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlm_trainer.fit(mlm_model, mlm_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "83c3bc64cdb2fa57c90e4138bece6a48e4148d75db176957f4eccfc04658c255"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
