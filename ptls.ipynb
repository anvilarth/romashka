{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch \n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from models import TransactionsModel\n",
    "from data_generators import batches_generator, cat_features_names, num_features_names, meta_features_names\n",
    "\n",
    "from embedding import EmbeddingLayer\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.frames.bert import MLMPretrainModule\n",
    "\n",
    "from ptls.nn import RnnSeqEncoder\n",
    "from ptls.nn import TransformerEncoder\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./assets/num_embedding_projections.pkl', 'rb') as f:\n",
    "    num_embedding_projections = pickle.load(f)\n",
    "    \n",
    "with open('./assets/cat_embedding_projections.pkl', 'rb') as f:\n",
    "    cat_embedding_projections = pickle.load(f)\n",
    "\n",
    "with open('./assets/meta_embedding_projections.pkl', 'rb') as f:\n",
    "    meta_embedding_projections = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddedBatch:\n",
    "    def __init__(self, data):\n",
    "        self.payload = data\n",
    "        self.seq_lens = torch.LongTensor([data.shape[1]] * data.shape[0]).to(device)\n",
    "        \n",
    "class IterDataset(IterableDataset):\n",
    "    def __init__(self, dataset_train, batch_size=64, device='cuda'):\n",
    "        self.data = dataset_train\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.foo = lambda: batches_generator(self.data, batch_size=self.batch_size, shuffle=True, device=self.device, is_train=True, output_format='torch', min_seq_len=200)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = '/home/jovyan/afilatov/data/alfa/train_buckets'\n",
    "\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_train = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])[0:1]\n",
    "\n",
    "#train_dataloader = batches_generator(dataset_train, batch_size=64, shuffle=True,\n",
    "#                                            device=device, is_train=True, output_format='torch', min_seq_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IterDataset(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PtlsEmbeddingLayer(EmbeddingLayer):\n",
    "    def __init__(self, splitter, *args, **kwargs):\n",
    "        self.splitter = splitter\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.output_size = self.get_embedding_size()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = super().forward(x)\n",
    "        return PaddedBatch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySampleUniform:\n",
    "    \"\"\"\n",
    "    Sub samples with equal length = `seq_len`\n",
    "    Start pos has fixed uniform distribution from sequence start to end with equal step\n",
    "    |---------------------|       main sequence\n",
    "    |------|              |        sub seq 1\n",
    "    |    |------|         |        sub seq 2\n",
    "    |         |------|    |        sub seq 3\n",
    "    |              |------|        sub seq 4\n",
    "    There is no random factor in this splitter, so sub sequences are the same every time\n",
    "    Can be used during inference as test time augmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, split_count, seq_len, **_):\n",
    "        self.split_count = split_count\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def split(self, dates):\n",
    "        date_len = dates.shape[0]\n",
    "        date_range = np.arange(date_len)\n",
    "\n",
    "        if date_len <= self.seq_len + self.split_count:\n",
    "            return [date_range for _ in range(self.split_count)]\n",
    "\n",
    "        start_pos = np.linspace(0, date_len - self.seq_len, self.split_count).round().astype(int)\n",
    "        return [date_range[s:s + self.seq_len] for s in start_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_process(batch, splitter):\n",
    "    res = {}\n",
    "    \n",
    "    local_date = batch['event_time']\n",
    "    indexes = splitter.split(local_date)\n",
    "    \n",
    "    for k, v in batch.items():\n",
    "        if type(v) == list and len(v) > 1:\n",
    "            new_v = []\n",
    "            for elem in v:\n",
    "                tmp = []\n",
    "                for i, ix in enumerate(indexes):\n",
    "                    to_tmp = elem[:, ix]\n",
    "                    if i == 0:\n",
    "                        pad_size = to_tmp.shape[1]\n",
    "                    else:\n",
    "                        if to_tmp.shape[1] < pad_size:\n",
    "                            to_tmp = torch.cat([\n",
    "                                to_tmp, torch.zeros(to_tmp.shape[0], pad_size - to_tmp.shape[1]).to(device)\n",
    "                            ], axis=1)\n",
    "                    tmp.append(to_tmp)\n",
    "                new_v.append(torch.cat(tmp, dim=0))\n",
    "        else:\n",
    "            new_v = v \n",
    "        res[k] = new_v\n",
    "    return res\n",
    "\n",
    "def my_collate_fn(batch, splitter):\n",
    "    batch = batch[0]\n",
    "    len_batch = batch['num_features'][0].shape[0]\n",
    "    batch = split_process(batch, splitter)\n",
    "    # print(batch)\n",
    "    labels = torch.arange(len_batch).repeat(5)\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.frames import PtlsDataModule\n",
    "\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.data_load.utils import collate_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coles_splitter = MySampleUniform(\n",
    "        split_count=5,\n",
    "        seq_len=100\n",
    "    )\n",
    "\n",
    "ptls_emb_layer = PtlsEmbeddingLayer(coles_splitter,\n",
    "                                    cat_embedding_projections,\n",
    "                                    cat_features_names,\n",
    "                                    num_embedding_projections,\n",
    "                                    num_features_names).cuda()\n",
    "seq_encoder = RnnSeqEncoder(\n",
    "    input_size=ptls_emb_layer.get_embedding_size(),\n",
    "    trx_encoder=ptls_emb_layer,\n",
    "    hidden_size=256,\n",
    "    type='gru',\n",
    ")\n",
    "\n",
    "model = CoLESModule(\n",
    "    seq_encoder=seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9),\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coles_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=partial(my_collate_fn, splitter=coles_splitter),\n",
    "    num_workers=0,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import logging\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    gpus=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 352 K \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "352 K     Trainable params\n",
      "0         Non-trainable params\n",
      "352 K     Total params\n",
      "1.409     Total estimated model params size (MB)\n",
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 255 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c02519a3274da9b0b00f15f876a77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# %debug\n",
    "trainer.fit(model, coles_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.frames.cpc import CpcModule\n",
    "from ptls.frames.coles.split_strategy import SampleSlices, SampleUniformBySplitCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_splitter = SampleUniformBySplitCount(split_count=5) # splitter should preserve order in samples\n",
    "\n",
    "cpc_ptls_emb_layer = PtlsEmbeddingLayer(cpc_splitter,\n",
    "                                        cat_embedding_projections,\n",
    "                                        cat_features_names,\n",
    "                                        num_embedding_projections,\n",
    "                                        num_features_names).cuda()\n",
    "\n",
    "cpc_seq_encoder = RnnSeqEncoder(\n",
    "    input_size=cpc_ptls_emb_layer.get_embedding_size(),\n",
    "    trx_encoder=cpc_ptls_emb_layer,\n",
    "    hidden_size=256,\n",
    "    type='gru',\n",
    ")\n",
    "\n",
    "cpc_model = CpcModule(\n",
    "    seq_encoder=cpc_seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=5, gamma=0.9)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    collate_fn=partial(my_collate_fn, splitter=cpc_splitter),\n",
    "    num_workers=0,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "cpc_trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    gpus=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type          | Params\n",
      "-----------------------------------------------------\n",
      "0 | _loss              | CPC_Loss      | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder | 352 K \n",
      "2 | _validation_metric | CpcAccuracy   | 0     \n",
      "3 | _linears           | ModuleList    | 280 K \n",
      "-----------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.532     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6407919da84153abfc6eef78e1946c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%debug\n",
    "cpc_trainer.fit(cpc_model, cpc_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "83c3bc64cdb2fa57c90e4138bece6a48e4148d75db176957f4eccfc04658c255"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
